namespace weka.classifiers.meta;

class ClassificationViaRegression
{
  isA TechnicalInformationHandler;
  isA SingleClassifierEnhancer;
 depend weka.classifiers.AbstractClassifier;
 depend weka.classifiers.Classifier;
 depend weka.classifiers.SingleClassifierEnhancer;
 depend weka.core.Capabilities;
 depend weka.core.Capabilities.Capability;
 depend weka.core.Instance;
 depend weka.core.Instances;
 depend weka.core.RevisionUtils;
 depend weka.core.TechnicalInformation;
 depend weka.core.TechnicalInformation.Field;
 depend weka.core.TechnicalInformation.Type;
 depend weka.core.TechnicalInformationHandler;
 depend weka.core.Utils;
 depend weka.core.UnassignedClassException;
 depend weka.filters.Filter;
 depend weka.filters.unsupervised.attribute.MakeIndicator;
/** 
 * for serialization 
 */
static final long serialVersionUID=4500023123618669859L;

/** 
 * The classifiers. (One for each class.) 
 */
private Classifier[] m_Classifiers;

/** 
 * The filters used to transform the class. 
 */
private MakeIndicator[] m_ClassFilters;

/** 
 * Default constructor.
 */
public ClassificationViaRegression(){
  m_Classifier=new weka.classifiers.trees.M5P();
}

/** 
 * Returns a string describing classifier
 * @return a description suitable fordisplaying in the explorer/experimenter gui
 */
public String globalInfo(){
  return "Class for doing classification using regression methods. Class is " + "binarized and one regression model is built for each class value. For more " + "information, see, for example\n\n"+ getTechnicalInformation().toString();
}

/** 
 * Returns an instance of a TechnicalInformation object, containing  detailed information about the technical background of this class, e.g., paper reference or book this class is based on.
 * @return the technical information about this class
 */
public TechnicalInformation getTechnicalInformation(){
  TechnicalInformation result;
  result=new TechnicalInformation(Type.ARTICLE);
  result.setValue(Field.AUTHOR,"E. Frank and Y. Wang and S. Inglis and G. Holmes and I.H. Witten");
  result.setValue(Field.YEAR,"1998");
  result.setValue(Field.TITLE,"Using model trees for classification");
  result.setValue(Field.JOURNAL,"Machine Learning");
  result.setValue(Field.VOLUME,"32");
  result.setValue(Field.NUMBER,"1");
  result.setValue(Field.PAGES,"63-76");
  return result;
}

/** 
 * String describing default classifier.
 * @return the default classifier classname
 */
protected String defaultClassifierString(){
  return "weka.classifiers.trees.M5P";
}

/** 
 * Returns default capabilities of the classifier.
 * @return      the capabilities of this classifier
 */
public Capabilities getCapabilities(){
  Capabilities result=super.getCapabilities();
  result.disableAllClasses();
  result.disableAllClassDependencies();
  result.enable(Capability.NOMINAL_CLASS);
  return result;
}

/** 
 * Builds the classifiers.
 * @param insts the training data.
 * @throws Exception if a classifier can't be built
 */
public void buildClassifier(Instances insts) throws Exception {
  Instances newInsts;
  getCapabilities().testWithFail(insts);
  insts=new Instances(insts);
  insts.deleteWithMissingClass();
  m_Classifiers=AbstractClassifier.makeCopies(m_Classifier,insts.numClasses());
  m_ClassFilters=new MakeIndicator[insts.numClasses()];
  for (int i=0; i < insts.numClasses(); i++) {
    m_ClassFilters[i]=new MakeIndicator();
    m_ClassFilters[i].setAttributeIndex("" + (insts.classIndex() + 1));
    m_ClassFilters[i].setValueIndex(i);
    m_ClassFilters[i].setNumeric(true);
    m_ClassFilters[i].setInputFormat(insts);
    newInsts=Filter.useFilter(insts,m_ClassFilters[i]);
    m_Classifiers[i].buildClassifier(newInsts);
  }
}

/** 
 * Returns the distribution for an instance.
 * @param inst the instance to get the distribution for
 * @return the computed distribution
 * @throws Exception if the distribution can't be computed successfully
 */
public double[] distributionForInstance(Instance inst) throws Exception {
  double[] probs=new double[inst.numClasses()];
  Instance newInst;
  double sum=0;
  for (int i=0; i < inst.numClasses(); i++) {
    m_ClassFilters[i].input(inst);
    m_ClassFilters[i].batchFinished();
    newInst=m_ClassFilters[i].output();
    probs[i]=m_Classifiers[i].classifyInstance(newInst);
    if (Utils.isMissingValue(probs[i])) {
      throw new UnassignedClassException("ClassificationViaRegression: base learner predicted missing value.");
    }
    if (probs[i] > 1) {
      probs[i]=1;
    }
    if (probs[i] < 0) {
      probs[i]=0;
    }
    sum+=probs[i];
  }
  if (sum != 0) {
    Utils.normalize(probs,sum);
  }
  return probs;
}

/** 
 * Prints the classifiers.
 * @return a string representation of the classifier
 */
public String toString(){
  if (m_Classifiers == null) {
    return "Classification via Regression: No model built yet.";
  }
  StringBuffer text=new StringBuffer();
  text.append("Classification via Regression\n\n");
  for (int i=0; i < m_Classifiers.length; i++) {
    text.append("Classifier for class with index " + i + ":\n\n");
    text.append(m_Classifiers[i].toString() + "\n\n");
  }
  return text.toString();
}

/** 
 * Returns the revision string.
 * @return		the revision
 */
public String getRevision(){
  return RevisionUtils.extract("$Revision: 10470 $");
}

/** 
 * Main method for testing this class.
 * @param argv the options for the learner
 */
public static void main(String[] argv){
  runClassifier(new ClassificationViaRegression(),argv);
}
}
